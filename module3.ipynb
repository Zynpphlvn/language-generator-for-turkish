{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random as rnd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from os.path import join\n",
    "from jpype import JClass, getDefaultJVMPath, java, shutdownJVM, startJVM\n",
    "import nltk.data\n",
    "import codecs\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ZEMBEREK_PATH: str = join('..', '..', 'bin', 'zemberek-full.jar')\n",
    "\n",
    "    startJVM(\n",
    "            getDefaultJVMPath(),\n",
    "            '-ea',\n",
    "            f'-Djava.class.path={\"C://Users//ASUS//Desktop//cz//distributions//0.17.1//zemberek-full.jar\"}',\n",
    "            convertStrings=False\n",
    "    )\n",
    "   \n",
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    Paths: JClass = JClass('java.nio.file.Paths')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "path = \"C://Users//ASUS//Desktop//cz//1150haberAZ//siyasi\"\n",
    "fileNames = []\n",
    "wordList = []\n",
    "\n",
    "fileNames = [ subdir+os.path.sep+file for subdir, dirs, files in os.walk(path) for file in files ]\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(decode_error='ignore')\n",
    "docTermMatrix = tfidfVectorizer.fit_transform((open(f,encoding=\"utf8\").read() for f in fileNames))\n",
    "\n",
    "wordList = [ word[0] for word in tfidfVectorizer.vocabulary_.items() ]\n",
    "verb_list = []\n",
    "\n",
    "for f in fileNames:\n",
    "    doc = codecs.open(f, 'r', 'utf-8')\n",
    "    content = doc.read()\n",
    "\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/turkish.pickle')\n",
    "    tokenized_sentence = tokenizer.tokenize(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from os.path import join\n",
    "from jpype import JClass, JString, getDefaultJVMPath, java, shutdownJVM, startJVM\n",
    "\n",
    "\n",
    "def find_synonyms(sentence):   \n",
    "    global new_sentence\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "#     print(\"ORIGINAL SENTENCE: \" + sentence)\n",
    "    return_sentence = \"\"\n",
    "    sentence_words = []\n",
    "    sentence_for_synonym_search = []\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        ZEMBEREK_PATH: str = join('..', '..', 'bin', 'zemberek-full.jar')\n",
    "\n",
    "        TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "        Paths: JClass = JClass('java.nio.file.Paths')\n",
    "\n",
    "        morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "    \n",
    "    for i in sentence.split():\n",
    "        sentence: str = i\n",
    "        analysis: java.util.ArrayList = morphology.analyzeSentence(sentence)\n",
    "\n",
    "        results: java.util.ArrayList = (\n",
    "            morphology.disambiguate(sentence, analysis).bestAnalysis()\n",
    "        )\n",
    "        \n",
    "        #add sentence just subject, adjective, noun and verb from original sentence\n",
    "        for j, result in enumerate(results, start=0):\n",
    "            x = (str(result)).split(\":\")[1]\n",
    "            y = x.split(\"]\")[0]\n",
    "            if y == \"Pron,Pers\": #Select Subject Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Adj\": #Select Adj Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Noun\": #Select Noun Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Verb\": #Select Verb Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "\n",
    "    word_new = \"\"\n",
    "    \n",
    "    for kelime,original_word in zip(sentence_for_synonym_search,sentence_words):\n",
    "        kelime_new = kelime.replace('ö','o')\n",
    "        kelime_new = kelime_new.replace('ı','i')\n",
    "        kelime_new = kelime_new.replace('ü','u')\n",
    "        kelime_new = kelime_new.replace('ç','c')\n",
    "        kelime_new = kelime_new.replace('ş','s')\n",
    "        kelime_new = kelime_new.replace('ğ','g')\n",
    "        kelime_new = kelime_new.strip()\n",
    "#         print(\"KELIME_NEW: \" + kelime_new)\n",
    "        #find synonyms from site\n",
    "#         try:\n",
    "\n",
    "        if kelime not in verb_list:\n",
    "            user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "\n",
    "            url = \"http://www.es-anlam.com/kelime/\" + kelime_new\n",
    "            headers={'User-Agent':user_agent,} \n",
    "\n",
    "            request=urllib.request.Request(url,None,headers) #The assembled request\n",
    "            response = urllib.request.urlopen(request)\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            ana = soup.find('h2')\n",
    "            alt=ana.find('strong')\n",
    "            alt = str(alt)\n",
    "            alt = (alt.split(\">\")[1]).split(\",\")[0]\n",
    "            alt = alt.split(\"<\")[0]\n",
    "            alt = alt.strip()\n",
    "\n",
    "            if alt == \"BULUNAMADI !\":\n",
    "                new_sentence = new_sentence + \" \" + original_word\n",
    "            else:\n",
    "#                 new_sentence = new_sentence + \" \" + alt\n",
    "                word_new = alt\n",
    "\n",
    "                add_suffix(original_word, word_new)   \n",
    "#             print(\"NEW_SENTENCE IF: \" + new_sentence)\n",
    "    \n",
    "        else:\n",
    "            new_sentence += \" \" + original_word\n",
    "#             print(\"NEW_SENTENCE ELSE: \" + new_sentence)\n",
    "\n",
    "    return new_sentence\n",
    "    \n",
    "\n",
    "def add_suffix(sentence_word, synonym_word):\n",
    "    global new_sentence\n",
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    WordAnalysis: JClass = JClass('zemberek.morphology.analysis.WordAnalysis')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "    \n",
    "    results: WordAnalysis = morphology.analyze(JString(sentence_word))\n",
    "\n",
    "    number = \"\"\n",
    "    possessive = \"\"\n",
    "    case = \"\"\n",
    "    word = \"\"\n",
    "\n",
    "    for result in results:\n",
    "        result = str(result)\n",
    "        try:#set number\n",
    "            if \"A3sg\" in result:\n",
    "                number = \"A3sg\"\n",
    "            elif \"A3pl\" in result:\n",
    "                number = \"A3pl\"\n",
    "        except:\n",
    "            number = \"\"\n",
    "        \n",
    "        try: #set possessive\n",
    "            if \"P1sg\" in result:\n",
    "                possessive =\"P1sg\"\n",
    "            elif \"P2sg\" in results:\n",
    "                possessive = \"P2sg\"\n",
    "            elif \"P3sg\" in result:\n",
    "                possessive = \"P3sg\"\n",
    "        except:\n",
    "            possessive = \"\"\n",
    "        \n",
    "        try: #set case\n",
    "            if \"Dat\" in result:\n",
    "                case = \"Dat\"\n",
    "            elif \"Loc\" in result:\n",
    "                case = \"Loc\"\n",
    "            elif \"Abl\" in result:\n",
    "                case = \"Abl\"\n",
    "        except:\n",
    "            case = \"\"   #cases: List[JString] = [JString('Dat'), JString('Loc'), JString('Abl')]\n",
    "        \n",
    "        word = result.split(\" \")[1]\n",
    "        word = word.split(\":\")[0]\n",
    "\n",
    "    morphology: TurkishMorphology = (\n",
    "        TurkishMorphology.builder().setLexicon(synonym_word).disableCache().build()\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        item = morphology.getLexicon().getMatchingItems(synonym_word).get(0)\n",
    "\n",
    "        if number != \"\" and possessive != \"\" and case != \"\":\n",
    "            for result in morphology.getWordGenerator().generate(item, number, possessive, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive != \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number, possessive):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive == \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive != \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, possessive, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive == \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive != \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, possessive):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive == \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        else:\n",
    "            new_sentence += str(result.surface)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueList(word_list):\n",
    "    \n",
    "    letterValue = {'a':1, 'b':2, 'c':3, 'ç':4, 'd':5, 'e':6, 'f':7, 'g':8, 'ğ':9, 'h':10, 'ı':11,\n",
    "                 'i':12, 'j':13, 'k':14, 'l':15, 'm':16, 'n':17, 'o':18, 'ö':19, 'p':20, 'r':21,\n",
    "                 's':22, 'ş':23, 't':24, 'u':25, 'ü':26, 'v':27, 'y':28, 'z':29 }\n",
    "    values = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        total = 0      \n",
    "        for letter in word:\n",
    "            if letter not in letterValue:\n",
    "                continue\n",
    "            total = total + letterValue[letter]\n",
    "            \n",
    "        values.append(total)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING SENTENCE, PLEASE WAIT...\n",
      "Gülün maneviyadı düzeldi\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"\" #global sentence for generating new sentence\n",
    "\n",
    "def generate_sentence():\n",
    "    global verb_list\n",
    "    global new_sentence\n",
    "    sentence_sum = 300 #SENTENCE VALUE\n",
    "    \n",
    "    for i in wordList:\n",
    "        sentence: str = i\n",
    "        analysis: java.util.ArrayList = morphology.analyzeSentence(sentence)\n",
    "\n",
    "        results: java.util.ArrayList = (\n",
    "            morphology.disambiguate(sentence, analysis).bestAnalysis()\n",
    "        )\n",
    "        \n",
    "        for j, result in enumerate(results, start=0):\n",
    "            x = (str(result)).split(\":\")[1]\n",
    "            y = x.split(\"]\")[0]\n",
    "\n",
    "            if y == \"Verb\": #Select Verb Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                verb_list.append(y)\n",
    "                verb_list = list(dict.fromkeys(verb_list))\n",
    "\n",
    "    gen_sentence_list = []\n",
    "    sentence_value = 0\n",
    "    cntrl = 0\n",
    "\n",
    "    print(\"GENERATING SENTENCE, PLEASE WAIT...\")\n",
    "    for sentence in tokenized_sentence:\n",
    "        if cntrl == 1:\n",
    "            new_sentence = \"\"\n",
    "        synonym_sentence = \"\"\n",
    "        synonym_sentence = find_synonyms(sentence)\n",
    "        synonym_sentence = synonym_sentence[1:]\n",
    "        new_sentence = synonym_sentence.capitalize()\n",
    "#         print(\"NEW SENTENCE: \" + new_sentence)\n",
    "        cntrl = 1\n",
    "        \n",
    "        sentence_value = valueList(synonym_sentence)\n",
    "        \n",
    "        total_value = 0\n",
    "        for value in sentence_value:\n",
    "            total_value += value\n",
    "            \n",
    "#         print(total_value)\n",
    "\n",
    "            \n",
    "        if total_value <= sentence_sum+100 and total_value > sentence_sum:\n",
    "            gen_sentence_list.append(new_sentence)\n",
    "            \n",
    "        if len(gen_sentence_list) == 1:\n",
    "            break\n",
    "               \n",
    "    for i in gen_sentence_list:\n",
    "        print(i)   \n",
    "    \n",
    "generate_sentence()\n",
    "shutdownJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
